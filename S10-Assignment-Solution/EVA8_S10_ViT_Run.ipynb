{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIi2DoAyqs7pw0dYxL6Tie",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b6b2a87730d34fecb39ccb74d84f454d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_092e7fce4afb4945b66f1e90486c83f8",
              "IPY_MODEL_64e1201587a64952828f41243357ca2a",
              "IPY_MODEL_a03538f95c4442aa998d0ace2b8e53fd"
            ],
            "layout": "IPY_MODEL_09758f283e1541d1aac39f2d27197912"
          }
        },
        "092e7fce4afb4945b66f1e90486c83f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13e77d4b6d674e4aaf5f007cfe796181",
            "placeholder": "​",
            "style": "IPY_MODEL_387a472dad8344beb735e7544c66e943",
            "value": "100%"
          }
        },
        "64e1201587a64952828f41243357ca2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e40f2bb15ae4538976a2834025c165d",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59cb54bc0dba4fd9bfb3897452d5333a",
            "value": 170498071
          }
        },
        "a03538f95c4442aa998d0ace2b8e53fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0860acaf5f74a809142b445fd5f304b",
            "placeholder": "​",
            "style": "IPY_MODEL_c60c9692628548efa692f8754046d14e",
            "value": " 170498071/170498071 [00:12&lt;00:00, 14892936.71it/s]"
          }
        },
        "09758f283e1541d1aac39f2d27197912": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13e77d4b6d674e4aaf5f007cfe796181": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "387a472dad8344beb735e7544c66e943": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e40f2bb15ae4538976a2834025c165d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59cb54bc0dba4fd9bfb3897452d5333a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0860acaf5f74a809142b445fd5f304b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c60c9692628548efa692f8754046d14e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peeyushsinghal/EVA8/blob/main/S10-Assignment-Solution/EVA8_S10_ViT_Run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Kbfmh5skceEs"
      },
      "outputs": [],
      "source": [
        "#@title importing libraries\n",
        "import numpy as np\n",
        "# from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5ufC_j2fImj",
        "outputId": "7389b5f9-d88d-47f7-d027-47b85f8d06d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title importing model\n",
        "\n",
        "\n",
        "def pair(data):\n",
        "  return data if isinstance(data,tuple) else (data,data)\n",
        "\n",
        "class ToPatch(nn.Module):\n",
        "  def __init__(self,  patch_size,  channels=3, embedding_dim = 768):\n",
        "    super().__init__()\n",
        "\n",
        "    self.patch= nn.Sequential(\n",
        "        nn.Conv2d(in_channels = channels, out_channels = embedding_dim, kernel_size = patch_size, stride = patch_size, padding =0), #3X32x32 -> out_channels x (image_height // patch_height) x (image_width // patch_width) [(out_channels)x(image_height // patch_height) x (image_width // patch_width)]\n",
        "        nn.Flatten(start_dim=2, end_dim=3), # conversion to 2d- out_channels x [(image_height // patch_height) x (image_width // patch_width)] == out_channels x num_patches\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.patch(x)\n",
        "    x = x.permute(0,2,1) # [B x out_channels x num_patches] -> [B x  num_patches x out_channels]\n",
        "    return x\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "  def __init__(self,\n",
        "               in_dim = 32,\n",
        "               out_dim = 3*32,\n",
        "               drop_out = 0.1\n",
        "               ):\n",
        "    super().__init__()\n",
        "    self.ff = nn.Sequential(\n",
        "        nn.Conv1d(in_channels=in_dim, out_channels=out_dim, kernel_size = 1), # using 1x1 conv instead of linear layer\n",
        "        nn.GELU(),\n",
        "        nn.Dropout(drop_out),\n",
        "        nn.Conv1d(in_channels=out_dim, out_channels=in_dim, kernel_size = 1), # using 1x1 conv instead of linear layer\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.ff(x)\n",
        "\n",
        "class TransformerEncoderBlock(nn.Module):\n",
        "  def __init__(self,  \n",
        "               num_heads = 4, # number of parallel multi attention heads required\n",
        "               dim = 32, # number of total dimension of input\n",
        "               transformer_dropout = 0.1 #Dropout used in feedforward layer\n",
        "               ):\n",
        "    super().__init__()\n",
        "    # attention block\n",
        "    self.layer_norm_preattn= nn.LayerNorm(dim)\n",
        "    self.self_attn = nn.MultiheadAttention(embed_dim = dim, \n",
        "                                           num_heads = num_heads,\n",
        "                                           batch_first = True)\n",
        "    \n",
        "\n",
        "    # mlp block\n",
        "    self.layer_norm_preff = nn.LayerNorm(dim)\n",
        "    self.feed_forward = FeedForward(in_dim = dim, out_dim = 3*dim, drop_out = transformer_dropout)\n",
        "\n",
        "  \n",
        "\n",
        "  def forward(self,x):\n",
        "    # attention block\n",
        "    x_attn_residual = self.layer_norm_preattn(x)\n",
        "    # print(\"after layer norm, size : \",x_attn_residual.shape)\n",
        "    x_attn_residual, attn_output_weights  = self.self_attn(query =x_attn_residual, \n",
        "                                            key = x_attn_residual, \n",
        "                                            value = x_attn_residual,\n",
        "                                            need_weights = True,\n",
        "                                            average_attn_weights=True)\n",
        "    # print(\"after attention, size : \",x_attn_residual.shape)\n",
        "    x = x + x_attn_residual\n",
        "    # print(\"after residual addition, size : \", x.shape) # batch, (num_patches + 1), (embedding_dim)\n",
        "\n",
        "    # Feed Forward block\n",
        "    x_ff_residual = self.layer_norm_preff(x)\n",
        "    x_ff_residual = self.feed_forward(x_ff_residual.permute(0,2,1)) # permutation required to get B x C x (num_patches + 1) format. C = Embedding Dim\n",
        "    # print(\"after feed forward, size : \", x_ff_residual.shape) \n",
        "    x = x + x_ff_residual.permute(0,2,1) # residual requires permutation to get back into format of x, i.e., B x(num_patches + 1) x C format. C = Embedding Dim\n",
        "    # print(\"after adding residual in feed forward, size : \", x_ff_residual.shape) \n",
        "    return x\n",
        "\n",
        "class TransformerStack(nn.Module):\n",
        "  ## MultiHead Attention Block\n",
        "  def __init__(self,\n",
        "               num_blocks = 4, # number of transformers blocks stacked on each other\n",
        "               num_heads = 4, # number of parallel multi attention heads required\n",
        "               dim = 32, # number of total dimension of input\n",
        "               transformer_dropout = 0.1 #Dropout used in attention\n",
        "               ):\n",
        "    super().__init__()\n",
        "    self.tranformer_stack = nn.ModuleList([]) # initialized\n",
        "    for _ in range(num_blocks):\n",
        "      self.tranformer_stack.append(TransformerEncoderBlock(num_heads=num_heads, dim = dim, transformer_dropout = transformer_dropout))\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    for transformer_block in self.tranformer_stack:\n",
        "      x = transformer_block(x)\n",
        "    return x\n",
        "\n",
        "class Head(nn.Module):\n",
        "  def __init__(self,\n",
        "               num_classes = 10, # number of classes\n",
        "               dim = 32, # input dimension\n",
        "               head_p_drop = 0.1 # drop out\n",
        "               ):\n",
        "    super().__init__()\n",
        "    self.layer_norm_prehead= nn.LayerNorm(dim)\n",
        "    self.head = nn.Sequential(\n",
        "        nn.GELU(),\n",
        "        nn.Dropout(head_p_drop),\n",
        "        nn.Conv1d(in_channels = dim, out_channels = num_classes, kernel_size = 1)\n",
        "    )\n",
        "\n",
        "  def forward(self,x, pool = 'cls'):\n",
        "    # print(\"before head block, size :\", x.shape)\n",
        "    if pool == 'cls':\n",
        "      x_cls = x[:,0,:] # getting the first dimension this gives [batch x dim]\n",
        "    else:\n",
        "      x_cls = x[:,1:,:].mean(dim=1) # ignoring the first dimension  this gives [batch x num_patch x dim], mean gives [batch x dim]\n",
        "    x_cls = x_cls.unsqueeze(dim=1) # [batch x dim] -> batch x 1 x dim\n",
        "    # print(\"before head block, before permutation, size :\", x_cls.shape)\n",
        "    x_cls = self.layer_norm_prehead(x_cls)\n",
        "    x_cls = x_cls.permute(0,2,1)\n",
        "    # print(\"before head block, after permutation, size :\", x_cls.shape)\n",
        "    x_cls = self.head(x_cls)\n",
        "    # print(\"after head block , size :\", x_cls.shape)\n",
        "    output = x_cls.view(-1,10)\n",
        "    \n",
        "    # if pool == 'mean':\n",
        "    #   x_mean = x[:,1:,:] # ignoring the first dimension  this gives [batch x num_patch x dim]\n",
        "    #   print(\"before taking mean, mean, size :\", x_mean.shape)\n",
        "    #   x_mean = x_mean.mean(dim =1) # this gives [batch x dim]\n",
        "    #   x_mean = x_mean.unsqueeze(dim=1) # [batch x dim] -> batch x 1 x dim\n",
        "    #   print(\"before head block, mean, size :\", x_mean.shape)\n",
        "    #   x_mean = self.layer_norm_prehead(x_mean)\n",
        "    #   print(\"before head block, after layernorm, mean, size :\", x_mean.shape)\n",
        "    #   x_mean = x_mean.permute(0,2,1)\n",
        "    #   print(\"before head block, after permutation, mean, size :\", x_mean.shape)\n",
        "    #   x_mean = self.head(x_mean)\n",
        "    #   print(\"after head block, mean, size :\", x_mean.shape)\n",
        "    #   output = x_mean.view(-1,10)\n",
        "    return output\n",
        "\n",
        "class ViT(nn.Module):\n",
        "  def __init__(self, \n",
        "               image_size, \n",
        "               patch_size, \n",
        "               dim = None, # if None, use the information as per image size else use the dimensions provided\n",
        "               pool = 'cls', # whether the pooling is based on class token ('cls') or mean pooling ('mean')\n",
        "               num_classes = 10, \n",
        "               emb_dropout = 0.1 #Dropout for patch and position embeddings\n",
        "               ):\n",
        "    super().__init__()\n",
        "    \n",
        "    assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
        "    self.pool = pool\n",
        "\n",
        "    image_height, image_width = pair(image_size)\n",
        "    patch_height, patch_width = pair(patch_size)\n",
        "\n",
        "    assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n",
        "\n",
        "    num_patches = (image_height // patch_height) * (image_width // patch_width)\n",
        "    channels = 3 # hard coding\n",
        "    patch_dim = channels * patch_height * patch_width\n",
        "\n",
        "    if dim:\n",
        "      embedding_dim = dim # specific dimension\n",
        "    else:\n",
        "      embedding_dim = patch_dim # 3xP_hxP_w\n",
        "\n",
        "    self.to_patch = ToPatch(patch_size = patch_size, channels = channels, embedding_dim = embedding_dim)\n",
        "    self.class_token = nn.Parameter(data= torch.randn(1, 1, embedding_dim), requires_grad=True)\n",
        "    self.pos_embedding = nn.Parameter(data = torch.randn(1, num_patches + 1, embedding_dim),requires_grad=True)\n",
        "    self.embedding_dropout = nn.Dropout(p=emb_dropout)\n",
        "\n",
        "    self.transformer = TransformerStack(num_blocks = 4,  num_heads = 4,  dim = 32,  transformer_dropout = 0.1)\n",
        "\n",
        "    self.head_output = Head(num_classes = num_classes, dim = embedding_dim, head_p_drop = 0.1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.to_patch(x)\n",
        "    # print(\"after to_patch, size :\", x.shape)\n",
        "    \n",
        "    batch_size, num_patches, embedding_dim = x.shape[0], x.shape[-2], x.shape[-1]\n",
        "    # print(f'num_patches : {num_patches}, embedding_dim : {embedding_dim}')\n",
        "    \n",
        "    class_token_across_batch = self.class_token.expand(batch_size,-1,-1) # -1 means not to expand in that direction\n",
        "    x = torch.cat((class_token_across_batch,x),dim=1) # dim 0 is batch_size, dim 1 is num_patches and dim 2 is embedding_dim\n",
        "    # print(\"after concatenation with class token, size :\", x.shape)\n",
        "    \n",
        "    pos_emeddings_across_batch = self.pos_embedding.expand(batch_size,-1,-1) # -1 means not to expand in that direction\n",
        "    x = x + pos_emeddings_across_batch \n",
        "    # print(\"after adding with postional embeddings, size :\", x.shape)\n",
        "\n",
        "    x = self.embedding_dropout(x)\n",
        "\n",
        "    x = self.transformer(x)\n",
        "    # print(\"after transformer, size :\", x.shape)\n",
        "\n",
        "    if self.pool == 'cls':\n",
        "      x = self.head_output(x,pool='cls')\n",
        "    if self.pool == 'mean':\n",
        "      x = self.head_output(x,pool='mean')\n",
        "\n",
        "    \n",
        "    # print(\"after head_output, size :\", x.shape)\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "y0zsDyRPdDez"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES, IMAGE_SIZE = 10, 32\n",
        "model = ViT( image_size = IMAGE_SIZE, patch_size=2, dim=32, pool = 'cls', num_classes= NUM_CLASSES)"
      ],
      "metadata": {
        "id": "zPCpMJrMfQQf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8-zFG7ofzRL",
        "outputId": "bed62937-10e1-4006-e2b3-20456e9ce2fb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ViT(\n",
              "  (to_patch): ToPatch(\n",
              "    (patch): Sequential(\n",
              "      (0): Conv2d(3, 32, kernel_size=(2, 2), stride=(2, 2))\n",
              "      (1): Flatten(start_dim=2, end_dim=3)\n",
              "    )\n",
              "  )\n",
              "  (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
              "  (transformer): TransformerStack(\n",
              "    (tranformer_stack): ModuleList(\n",
              "      (0): TransformerEncoderBlock(\n",
              "        (layer_norm_preattn): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
              "        )\n",
              "        (layer_norm_preff): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "        (feed_forward): FeedForward(\n",
              "          (ff): Sequential(\n",
              "            (0): Conv1d(32, 96, kernel_size=(1,), stride=(1,))\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Dropout(p=0.1, inplace=False)\n",
              "            (3): Conv1d(96, 32, kernel_size=(1,), stride=(1,))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): TransformerEncoderBlock(\n",
              "        (layer_norm_preattn): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
              "        )\n",
              "        (layer_norm_preff): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "        (feed_forward): FeedForward(\n",
              "          (ff): Sequential(\n",
              "            (0): Conv1d(32, 96, kernel_size=(1,), stride=(1,))\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Dropout(p=0.1, inplace=False)\n",
              "            (3): Conv1d(96, 32, kernel_size=(1,), stride=(1,))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): TransformerEncoderBlock(\n",
              "        (layer_norm_preattn): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
              "        )\n",
              "        (layer_norm_preff): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "        (feed_forward): FeedForward(\n",
              "          (ff): Sequential(\n",
              "            (0): Conv1d(32, 96, kernel_size=(1,), stride=(1,))\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Dropout(p=0.1, inplace=False)\n",
              "            (3): Conv1d(96, 32, kernel_size=(1,), stride=(1,))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): TransformerEncoderBlock(\n",
              "        (layer_norm_preattn): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
              "        )\n",
              "        (layer_norm_preff): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "        (feed_forward): FeedForward(\n",
              "          (ff): Sequential(\n",
              "            (0): Conv1d(32, 96, kernel_size=(1,), stride=(1,))\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Dropout(p=0.1, inplace=False)\n",
              "            (3): Conv1d(96, 32, kernel_size=(1,), stride=(1,))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head_output): Head(\n",
              "    (layer_norm_prehead): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "    (head): Sequential(\n",
              "      (0): GELU(approximate='none')\n",
              "      (1): Dropout(p=0.1, inplace=False)\n",
              "      (2): Conv1d(32, 10, kernel_size=(1,), stride=(1,))\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of parameters: {:,}\".format(sum(p.numel() for p in model.parameters())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpWRJDpVf-pp",
        "outputId": "0c351827-1d12-4827-847f-657fe0526141"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 51,562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 32\n",
        "\n",
        "NUM_CLASSES = 10\n",
        "NUM_WORKERS = 8\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 25\n",
        "\n",
        "LEARNING_RATE = 1e-3\n",
        "WEIGHT_DECAY = 1e-1\n",
        "\n",
        "cifar10_mean = (0.4914, 0.4822, 0.4465)\n",
        "cifar10_std = (0.2471, 0.2435, 0.2616)\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(32, scale=(0.75, 1.0), ratio=(1.0, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandAugment(num_ops=1, magnitude=8),\n",
        "    transforms.ColorJitter(0.1, 0.1, 0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(cifar10_mean, cifar10_std),\n",
        "    transforms.RandomErasing(p=0.25)\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(cifar10_mean, cifar10_std)\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=train_transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True, num_workers=4)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=test_transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
        "                                         shuffle=False, num_workers=4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160,
          "referenced_widgets": [
            "b6b2a87730d34fecb39ccb74d84f454d",
            "092e7fce4afb4945b66f1e90486c83f8",
            "64e1201587a64952828f41243357ca2a",
            "a03538f95c4442aa998d0ace2b8e53fd",
            "09758f283e1541d1aac39f2d27197912",
            "13e77d4b6d674e4aaf5f007cfe796181",
            "387a472dad8344beb735e7544c66e943",
            "9e40f2bb15ae4538976a2834025c165d",
            "59cb54bc0dba4fd9bfb3897452d5333a",
            "a0860acaf5f74a809142b445fd5f304b",
            "c60c9692628548efa692f8754046d14e"
          ]
        },
        "id": "vehWvs64OrAS",
        "outputId": "3f9e0901-19af-42e6-e2fc-31dcbeafb5dc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6b2a87730d34fecb39ccb74d84f454d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "clip_norm = True\n",
        "lr_schedule = lambda t: np.interp([t], [0, EPOCHS*2//5, EPOCHS*4//5, EPOCHS], \n",
        "                                  [0, 0.01, 0.01/20.0, 0])[0]\n",
        "\n",
        "# model = nn.DataParallel(model, device_ids=[0]).cuda()\n",
        "opt = optim.AdamW(model.parameters(), lr=0.01, weight_decay=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    train_loss, train_acc, n = 0, 0, 0\n",
        "    for i, (X, y) in enumerate(trainloader):\n",
        "        model.train()\n",
        "        X, y = X.cuda(), y.cuda()\n",
        "\n",
        "        lr = lr_schedule(epoch + (i + 1)/len(trainloader))\n",
        "        opt.param_groups[0].update(lr=lr)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            output = model(X)\n",
        "            loss = criterion(output, y)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        if clip_norm:\n",
        "            scaler.unscale_(opt)\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        scaler.step(opt)\n",
        "        scaler.update()\n",
        "        \n",
        "        train_loss += loss.item() * y.size(0)\n",
        "        train_acc += (output.max(1)[1] == y).sum().item()\n",
        "        n += y.size(0)\n",
        "        \n",
        "    model.eval()\n",
        "    test_acc, m = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for i, (X, y) in enumerate(testloader):\n",
        "            X, y = X.cuda(), y.cuda()\n",
        "            with torch.cuda.amp.autocast():\n",
        "                output = model(X)\n",
        "            test_acc += (output.max(1)[1] == y).sum().item()\n",
        "            m += y.size(0)\n",
        "\n",
        "    print(f'ViT: Epoch: {epoch} | Train Acc: {train_acc/n:.4f}, Test Acc: {test_acc/m:.4f}, Time: {time.time() - start:.1f}, lr: {lr:.6f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ow0DNajbO0dx",
        "outputId": "d887a955-2c29-438d-9318-0b36d3685532"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ViT: Epoch: 0 | Train Acc: 0.1780, Test Acc: 0.2883, Time: 71.9, lr: 0.001000\n",
            "ViT: Epoch: 1 | Train Acc: 0.2807, Test Acc: 0.3714, Time: 65.8, lr: 0.002000\n",
            "ViT: Epoch: 2 | Train Acc: 0.3436, Test Acc: 0.4328, Time: 64.1, lr: 0.003000\n",
            "ViT: Epoch: 3 | Train Acc: 0.3933, Test Acc: 0.4798, Time: 63.1, lr: 0.004000\n",
            "ViT: Epoch: 4 | Train Acc: 0.4330, Test Acc: 0.5002, Time: 65.6, lr: 0.005000\n",
            "ViT: Epoch: 5 | Train Acc: 0.4564, Test Acc: 0.5178, Time: 64.3, lr: 0.006000\n",
            "ViT: Epoch: 6 | Train Acc: 0.4816, Test Acc: 0.5498, Time: 64.9, lr: 0.007000\n",
            "ViT: Epoch: 7 | Train Acc: 0.4980, Test Acc: 0.5481, Time: 66.2, lr: 0.008000\n",
            "ViT: Epoch: 8 | Train Acc: 0.5129, Test Acc: 0.5611, Time: 63.8, lr: 0.009000\n",
            "ViT: Epoch: 9 | Train Acc: 0.5261, Test Acc: 0.5691, Time: 65.3, lr: 0.010000\n",
            "ViT: Epoch: 10 | Train Acc: 0.5385, Test Acc: 0.6042, Time: 64.7, lr: 0.009050\n",
            "ViT: Epoch: 11 | Train Acc: 0.5614, Test Acc: 0.6253, Time: 63.5, lr: 0.008100\n",
            "ViT: Epoch: 12 | Train Acc: 0.5723, Test Acc: 0.6294, Time: 65.4, lr: 0.007150\n",
            "ViT: Epoch: 13 | Train Acc: 0.5840, Test Acc: 0.6392, Time: 64.5, lr: 0.006200\n",
            "ViT: Epoch: 14 | Train Acc: 0.5929, Test Acc: 0.6500, Time: 64.5, lr: 0.005250\n",
            "ViT: Epoch: 15 | Train Acc: 0.6055, Test Acc: 0.6678, Time: 65.9, lr: 0.004300\n",
            "ViT: Epoch: 16 | Train Acc: 0.6233, Test Acc: 0.6817, Time: 64.0, lr: 0.003350\n",
            "ViT: Epoch: 17 | Train Acc: 0.6342, Test Acc: 0.6858, Time: 64.5, lr: 0.002400\n",
            "ViT: Epoch: 18 | Train Acc: 0.6477, Test Acc: 0.6881, Time: 66.7, lr: 0.001450\n",
            "ViT: Epoch: 19 | Train Acc: 0.6580, Test Acc: 0.7069, Time: 65.6, lr: 0.000500\n",
            "ViT: Epoch: 20 | Train Acc: 0.6696, Test Acc: 0.7092, Time: 65.1, lr: 0.000400\n",
            "ViT: Epoch: 21 | Train Acc: 0.6689, Test Acc: 0.7092, Time: 65.2, lr: 0.000300\n",
            "ViT: Epoch: 22 | Train Acc: 0.6719, Test Acc: 0.7111, Time: 64.6, lr: 0.000200\n",
            "ViT: Epoch: 23 | Train Acc: 0.6719, Test Acc: 0.7104, Time: 68.8, lr: 0.000100\n",
            "ViT: Epoch: 24 | Train Acc: 0.6747, Test Acc: 0.7112, Time: 63.9, lr: 0.000000\n"
          ]
        }
      ]
    }
  ]
}