{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peeyushsinghal/EVA8/blob/main/S6-Assignment-Solution/EVA8_S6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1FTBU_m-bRm"
      },
      "source": [
        "\n",
        "## Objective / Target \n",
        "* Write a single model.py file that includes GN/LN/BN and takes an argument to decide which normalization to include\n",
        "* Write a single notebook file to run all the 3 models above for 20 epochs each\n",
        "* Create these graphs:\n",
        "  * Graph 1: Test/Validation Loss for all 3 models together\n",
        "  * Graph 2: Test/Validation Accuracy for 3 models together\n",
        "  * graphs must have proper annotation\n",
        "* Find 10 misclassified images for each of the 3 models, and show them as a 5x2 image matrix in 3 separately annotated images. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcGwRKr5_lZw"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "D6yRS8Pc-GUk",
        "outputId": "ea0497fc-6f5c-4f86-bbe9-64a8a7c41bd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.8/dist-packages (1.5.1)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2d3b0e740210>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStepLR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mExponentialLR\u001b[0m \u001b[0;31m#scheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'model'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision import datasets,transforms\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt # for visualizing images\n",
        "import random # for random image index\n",
        "import torch.nn as nn # for network\n",
        "import torch.nn.functional as F # for forward method\n",
        "import torch.optim as optim # for optimizer\n",
        "!pip install torchsummary\n",
        "from torchsummary import summary # for model summary and params\n",
        "from tqdm import tqdm # for beautiful model training updates\n",
        "\n",
        "from torch.optim.lr_scheduler import StepLR,ReduceLROnPlateau,ExponentialLR #scheduler\n",
        "from model import Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0aDMenbFZMj"
      },
      "source": [
        "## Seed and Cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9TiFsydFcRz"
      },
      "outputs": [],
      "source": [
        "# check for cuda\n",
        "cuda = torch.cuda.is_available()\n",
        "print (f' Cuda Status : {cuda}')\n",
        "\n",
        "# setting seed\n",
        "SEED = 42 # arbit seed, why 42 - because in hitch hikers guide to galaxy it is answer to everything\n",
        "# torch.cuda.seed(SEED) \n",
        "torch.cuda.manual_seed_all(SEED) if cuda else torch.manual_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgga8EeQFB_r"
      },
      "source": [
        "## Data Transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrRWWXKsFBn7"
      },
      "outputs": [],
      "source": [
        "# Train Phase transformations\n",
        "train_transforms = transforms.Compose([\n",
        "                                      #  transforms.Resize((28, 28)),\n",
        "                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
        "                                       transforms.RandomRotation((-7.0, 7.0), fill=(1,)),\n",
        "                                       transforms.ToTensor(), # converts to tesnor\n",
        "                                       transforms.Normalize((0.1307,), (0.3081,)) # The mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values. \n",
        "                                       # Note the difference between (0.1307) and (0.1307,)\n",
        "                                       ])\n",
        "\n",
        "# Test Phase transformations\n",
        "test_transforms = transforms.Compose([\n",
        "                                      #  transforms.Resize((28, 28)),\n",
        "                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
        "                                       transforms.ToTensor(),# converts to tesnor\n",
        "                                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                       ])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvKkBT1KFIc9"
      },
      "source": [
        "## Dataset and Creating Train / Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdSmKv7XFNAY"
      },
      "outputs": [],
      "source": [
        "train = datasets.MNIST('./data', # directory where data needs to be stored\n",
        "                       train=True, # get the training portion of the dataset\n",
        "                       download=True, # downloads\n",
        "                       transform=train_transforms)\n",
        "test = datasets.MNIST('./data', \n",
        "                      train=False, \n",
        "                      download=True, \n",
        "                      transform=test_transforms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0mo-0V2GBUH"
      },
      "source": [
        "## Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFW6q5hWGDrb"
      },
      "outputs": [],
      "source": [
        "dataloader_args = dict(shuffle=True, batch_size=128, num_workers=4, pin_memory = True) if cuda else dict(shuffle=True, batch_size=64)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset=train,# train dataset\n",
        "    **dataloader_args # the dataloader arguments change dependent on cuda is available or not\n",
        "    )\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset = test,# test dataset \n",
        "    **dataloader_args # the dataloader arguments change dependent on cuda is available or not\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nR15hQnnGPuD"
      },
      "source": [
        "## Checking Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjuqXyw9GTDv"
      },
      "outputs": [],
      "source": [
        "images, labels  = next(iter(train_loader))\n",
        "print(images.shape)\n",
        "print(labels.shape)\n",
        "# printing random image and seeing\n",
        "plt.imshow(images[random.randint(0,len(images))].numpy().squeeze(), cmap='gray_r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yT5FD4C5Gbc1"
      },
      "outputs": [],
      "source": [
        "# Looking at more images\n",
        "figure = plt.figure()\n",
        "for index in range(1, len(images) + 1): # assumption: batch size would be atleast 8\n",
        "    plt.subplot(8, int(len(images)/8), index)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(images[index-1].numpy().squeeze(), cmap='gray_r')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNOv81RVGrgO"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_JHChueh7I5"
      },
      "outputs": [],
      "source": [
        "# class Network(nn.Module):\n",
        "#   def __init__(self, norm = 'bn'):\n",
        "#     super(Network,self).__init__() # extending super class method\n",
        "    \n",
        "#     drop_out_value = 0.1\n",
        "#     self.norm = norm\n",
        "\n",
        "#     # Input Block\n",
        "#     self.convblock1 = nn.Sequential(\n",
        "#         nn.Conv2d(1,18,3 , bias= False ), # In- 1x28x28, Out- 16x26x26, RF- 3x3, Jump_in -1, Jump_out -1\n",
        "#         nn.ReLU()\n",
        "#         # ,\n",
        "#         # nn.BatchNorm2d(18), # affine=False),\n",
        "#         # nn.Dropout(drop_out_value)\n",
        "#     ) \n",
        "    \n",
        "#     if self.norm == 'bn': self.normlayer1 = nn.BatchNorm2d(18)\n",
        "#     if self.norm == 'ln': self.normlayer1 = nn.LayerNorm([18,26,26]) \n",
        "#     if self.norm == 'gn' : self.normlayer1 = nn.GroupNorm(2,18) # 2 groups of 9 channels each\n",
        "#     self.dropout1 = nn.Dropout(drop_out_value)\n",
        "\n",
        "#     # Conv Block 2\n",
        "#     self.convblock2 = nn.Sequential(\n",
        "#         nn.Conv2d(18,16,3, bias= False ), # In- 16x26x26, Out- 16x24x24, RF- 5x5, Jump_in -1, Jump_out -1\n",
        "#         nn.ReLU()\n",
        "#         # ,\n",
        "#         # nn.BatchNorm2d(16),# affine=False),\n",
        "#         # nn.Dropout(drop_out_value)\n",
        "#     ) \n",
        "\n",
        "#     if self.norm == 'bn': self.normlayer2 = nn.BatchNorm2d(16)\n",
        "#     if self.norm == 'ln': self.normlayer2 = nn.LayerNorm([16,24,24]) \n",
        "#     if self.norm == 'gn' : self.normlayer2 = nn.GroupNorm(2,16) # 2 groups of 8 channels each\n",
        "#     self.dropout2 = nn.Dropout(drop_out_value)\n",
        "\n",
        "\n",
        "#     # Conv Block 3\n",
        "#     self.convblock3 = nn.Sequential(\n",
        "#         nn.Conv2d(16,16,3, bias= False ), # In- 16x24x24, Out- 16x22x22, RF- 7x7, Jump_in -1, Jump_out -1\n",
        "#         nn.ReLU()\n",
        "#         # ,\n",
        "#         # nn.BatchNorm2d(16),# affine=False),\n",
        "#         # nn.Dropout(drop_out_value)\n",
        "#     ) \n",
        "\n",
        "#     if self.norm == 'bn': self.normlayer3 = nn.BatchNorm2d(16)\n",
        "#     if self.norm == 'ln': self.normlayer3 = nn.LayerNorm([16,22,22]) \n",
        "#     if self.norm == 'gn' : self.normlayer3 = nn.GroupNorm(2,16) # 2 groups of 8 channels each\n",
        "#     self.dropout3 = nn.Dropout(drop_out_value)\n",
        "\n",
        "#     # Transition Block 1 (this also includes a conv block)\n",
        "#     self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # In- 16x22x22, Out- 16x11x11, RF- 8x8, Jump_in -1, Jump_out -2\n",
        "#     # self.convblock4 = nn.Sequential(\n",
        "#     #     nn.Conv2d(32,16,1), # In- 32x12x12, Out- 16x12x12, RF- 8x8, Jump_in -2, Jump_out -2\n",
        "#     #     nn.ReLU(),\n",
        "#     #     nn.BatchNorm2d(16),\n",
        "#     #     nn.Dropout(drop_out_value)\n",
        "#     # ) \n",
        "\n",
        "#     # Conv Block 5\n",
        "#     self.convblock5 = nn.Sequential(\n",
        "#         nn.Conv2d(16,16,3, bias= False ), # In- 16x11x11, Out- 16x9x9, RF- 12x12, Jump_in -2, Jump_out -2\n",
        "#         nn.ReLU()\n",
        "#         # ,\n",
        "#         # nn.BatchNorm2d(16),# affine=False),\n",
        "#         # nn.Dropout(drop_out_value)\n",
        "#     ) \n",
        "\n",
        "#     if self.norm == 'bn': self.normlayer5 = nn.BatchNorm2d(16)\n",
        "#     if self.norm == 'ln': self.normlayer5 = nn.LayerNorm([16,9,9]) \n",
        "#     if self.norm == 'gn' : self.normlayer5 = nn.GroupNorm(2,16) # 2 groups of 8 channels each\n",
        "#     self.dropout5 = nn.Dropout(drop_out_value)\n",
        "\n",
        "#     # Conv Block 6\n",
        "#     self.convblock6 = nn.Sequential(\n",
        "#         nn.Conv2d(16,16,3, bias= False ), # In- 16x9x9, Out- 16x7x7, RF- 16x16, Jump_in -2, Jump_out -2\n",
        "#         nn.ReLU()\n",
        "#         # ,\n",
        "#         # nn.BatchNorm2d(16),# affine=False),\n",
        "#         # nn.Dropout(drop_out_value)\n",
        "#     ) \n",
        "\n",
        "#     if self.norm == 'bn': self.normlayer6 = nn.BatchNorm2d(16)\n",
        "#     if self.norm == 'ln': self.normlayer6 = nn.LayerNorm([16,7,7]) \n",
        "#     if self.norm == 'gn' : self.normlayer6 = nn.GroupNorm(2,16) # 2 groups of 8 channels each\n",
        "#     self.dropout6 = nn.Dropout(drop_out_value)\n",
        "\n",
        "#     # Output Block\n",
        "#     self.convblock7 = nn.Sequential(\n",
        "#         nn.Conv2d(16,10,1, bias= False ), # In- 16x7x7, Out- 10x7x7, RF- 16x16, Jump_in -2, Jump_out -2\n",
        "#         # nn.ReLU()\n",
        "#         # ,\n",
        "#         # nn.BatchNorm2d(10, affine=True),\n",
        "#         # nn.Dropout(drop_out_value)\n",
        "#     ) \n",
        "\n",
        "#     self.gap = nn.AvgPool2d(7) # In- 10x7x7, Out- 10x1x1, RF- 16x16, Jump_in -2, Jump_out -2\n",
        "\n",
        "\n",
        "#   def forward(self,x):\n",
        "\n",
        "#     x = self.convblock1(x)\n",
        "#     x = self.dropout1(self.normlayer1(x))\n",
        "#     x = self.convblock2(x)\n",
        "#     x = self.dropout2(self.normlayer2(x))\n",
        "#     x = self.convblock3(x)\n",
        "#     x = self.dropout3(self.normlayer3(x))\n",
        "\n",
        "#     x = self.pool1(x)\n",
        "#     # x = self.convblock4(x)\n",
        "#     x = self.convblock5(x)\n",
        "#     x = self.dropout5(self.normlayer5(x))\n",
        "#     x = self.convblock6(x)\n",
        "#     x = self.dropout6(self.normlayer6(x))\n",
        "\n",
        "#     x = self.convblock7(x)\n",
        "\n",
        "#     x = self.gap(x)\n",
        "\n",
        "#     # Flattening\n",
        "#     x = x.view(-1,10)\n",
        "#     return F.log_softmax(x,dim=-1)\n",
        "\n",
        "# # model = Network()\n",
        "# # print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QSCWlFoM5nf"
      },
      "source": [
        "## Model Params and Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37ziIa80M8-3"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "print(device)\n",
        "model = Network(norm='gn').to(device)\n",
        "# print(model)\n",
        "summary(model, input_size=(1, 28, 28))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BriahAKX-Qsh"
      },
      "source": [
        "## Training and Testing Configuration and Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_bWJWRlHt2k"
      },
      "outputs": [],
      "source": [
        "mapping_dict = {'bn':'Batch Normalization', 'ln': 'Layer Normalization', 'gn': 'Group Normalization'}\n",
        "list_norm = ['bn','ln','gn']\n",
        "EPOCHS = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fP5jiQtaNPyB"
      },
      "outputs": [],
      "source": [
        "#@title Training Function\n",
        "# train_losses = [] # to capture train losses over training epochs\n",
        "# train_accuracy = [] # to capture train accuracy over training epochs\n",
        "\n",
        "def train(model,device, train_loader,optimizer,epoch,norm = None, lambda_l1 = 0.01):\n",
        "  model.train() # setting the model in training mode\n",
        "  pbar = tqdm(train_loader) # putting the iterator in pbar\n",
        "  correct = 0 # for accuracy numerator\n",
        "  processed = 0 # for accuracy denominator\n",
        "  avg_epoch_train_loss =[]\n",
        "\n",
        "  count = 0\n",
        "  for batch_idx, (images,labels) in enumerate(pbar):\n",
        "\n",
        "    images, labels = images.to(device),labels.to(device)#sending data to CPU or GPU as per device\n",
        "    optimizer.zero_grad() # setting gradients to zero to avoid accumulation\n",
        "\n",
        "    y_preds = model(images) # forward pass, result captured in y_preds (plural as there are many images in a batch)\n",
        "    # the predictions are in one hot vector\n",
        "\n",
        "    loss = F.nll_loss(y_preds,labels) # capturing loss\n",
        "\n",
        "    if norm == 'bn':\n",
        "      l1=0.0\n",
        "      for p in model.parameters():\n",
        "        l1 = l1 + p.abs().sum()\n",
        "      loss = loss + lambda_l1*l1\n",
        "    \n",
        "    avg_epoch_train_loss.append(loss.item())\n",
        "    \n",
        "    loss.backward() # backpropagation\n",
        "    optimizer.step() # updating the params\n",
        "\n",
        "    preds = y_preds.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "    correct += preds.eq(labels.view_as(preds)).sum().item()\n",
        "    processed += len(images)\n",
        "\n",
        "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}%')\n",
        "    train_accuracy = (100*correct/processed)\n",
        "    \n",
        "  return float(\"{:.4f}\".format(np.average(avg_epoch_train_loss))),float(\"{:.4f}\".format(np.average(train_accuracy)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXtm0lh_NR2H"
      },
      "outputs": [],
      "source": [
        "#@title Test Function\n",
        "\n",
        "\n",
        "def test(model,device, test_loader):\n",
        "  model.eval() # setting the model in evaluation mode\n",
        "  test_loss = 0\n",
        "  avg_epoch_test_loss =[]\n",
        "  correct = 0 # for accuracy numerator\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for (images,labels) in test_loader:\n",
        "      images, labels = images.to(device),labels.to(device)#sending data to CPU or GPU as per device\n",
        "      outputs = model(images) # forward pass, result captured in outputs (plural as there are many images in a batch)\n",
        "      # the outputs are in batch size x one hot vector \n",
        "\n",
        "      test_loss = F.nll_loss(outputs,labels, reduction='sum').item()  # sum up batch loss\n",
        "      preds = outputs.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "      correct += preds.eq(labels.view_as(preds)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset) # average test loss\n",
        "    avg_epoch_test_loss.append(test_loss)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "    test_loss, correct, len(test_loader.dataset),\n",
        "    100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "  return float(\"{:.4f}\".format(np.average(avg_epoch_test_loss))),float(\"{:.4f}\".format(correct/len(test_loader.dataset)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRnRZ72PNbf3"
      },
      "source": [
        "## Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3XZP8zQ3QlO"
      },
      "outputs": [],
      "source": [
        "\n",
        "## Weight initialization\n",
        "\n",
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Conv1d):\n",
        "      nn.init.xavier_normal_(m.weight)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLsLVH_C6e8m"
      },
      "outputs": [],
      "source": [
        "#@title Executing Training Function\n",
        "\n",
        "def execute_training(list_norm = ['bn'], Network = Network, epochs = 2 ):\n",
        "\n",
        "  dict_return ={}\n",
        "\n",
        "  for norm in list_norm:\n",
        "    print(f'=========training started for norm {norm}.========')\n",
        "    model =  Network(norm=norm).to(device)\n",
        "    model.apply(weights_init)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.3, momentum=0.9)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, factor = 0.1, patience = 2, threshold =  0.0002)\n",
        "\n",
        "    list_train_loss_temp = []\n",
        "    list_train_accuracy_temp = []\n",
        "    list_val_loss_temp =[]\n",
        "    list_val_accuracy_temp =[]\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(\"EPOCH:\", epoch+1)\n",
        "        train_loss, train_accuracy = train(model, device, train_loader, optimizer, epoch, norm = norm, lambda_l1 = 0.0001)\n",
        "        \n",
        "        list_train_loss_temp.append(train_loss)\n",
        "        list_train_accuracy_temp.append(train_accuracy)\n",
        "        scheduler.step(train_loss) \n",
        "\n",
        "        val_loss,val_accuracy = test(model, device, test_loader) \n",
        "\n",
        "        list_val_loss_temp.append(val_loss)\n",
        "        list_val_accuracy_temp.append(val_accuracy)\n",
        "         \n",
        "    print(f'=========training finished for norm {norm}.========')\n",
        "    dict_return[norm] = {'model': model,\n",
        "                         'train_loss':list_train_loss_temp,\n",
        "                         'val_loss': list_val_loss_temp,\n",
        "                         'train_accuracy':list_train_accuracy_temp,\n",
        "                         'val_accuracy':list_val_accuracy_temp}\n",
        "            \n",
        "  return dict_return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DF-4g0Y_AQH"
      },
      "outputs": [],
      "source": [
        "#@title Execution of Training and Test\n",
        "dict_training_output = {}\n",
        "dict_training_output = execute_training(list_norm = list_norm, Network = Network, epochs = EPOCHS )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LBA4lPoFqG3"
      },
      "outputs": [],
      "source": [
        "#@title Plot Images\n",
        "mapping_dict = {'bn':'Batch Normalization', 'ln': 'Layer Normalization', 'gn': 'Group Normalization'}\n",
        "fig, axs = plt.subplots(2,2,figsize=(15,10))\n",
        "for norm in list_norm:\n",
        "  axs[0, 0].plot(dict_training_output[norm]['train_loss'], label = mapping_dict[norm])\n",
        "  axs[0, 0].set_title(\"Training Loss\")\n",
        "  axs[0, 0].set_xlabel('number of epochs', fontsize=10)\n",
        "  axs[0, 0].set_ylabel('NLL Loss', fontsize=10)\n",
        "  axs[0, 0].legend()\n",
        "  axs[1, 0].plot(dict_training_output[norm]['train_accuracy'], label = mapping_dict[norm])\n",
        "  axs[1, 0].set_title(\"Training Accuracy\")\n",
        "  axs[1, 0].set_xlabel('number of epochs', fontsize=10)\n",
        "  axs[1, 0].set_ylabel('Accuracy in %', fontsize=10)\n",
        "  axs[1, 0].legend()\n",
        "  axs[0, 1].plot(dict_training_output[norm]['val_loss'], label = mapping_dict[norm])\n",
        "  axs[0, 1].set_title(\"Test Loss\")\n",
        "  axs[0, 1].set_xlabel('number of epochs', fontsize=10)\n",
        "  axs[0, 1].set_ylabel('NLL Loss', fontsize=10)\n",
        "  axs[0, 1].legend()\n",
        "  axs[1, 1].plot(dict_training_output[norm]['val_accuracy'], label = mapping_dict[norm])\n",
        "  axs[1, 1].set_title(\"Test Accuracy\")\n",
        "  axs[1, 1].set_xlabel('number of epochs', fontsize=10)\n",
        "  axs[1, 1].set_ylabel('Accuracy in %', fontsize=10)\n",
        "  axs[1, 1].legend()\n",
        "plt.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bng5hYqC0TyJ"
      },
      "outputs": [],
      "source": [
        "#@title Misclassified images\n",
        "\n",
        "def get_misclassified_images(model, device, test_loader, num_image = 10):\n",
        "  model.eval() # setting the model in evaluation mode\n",
        "  list_misclassified_images = []\n",
        "  with torch.no_grad():\n",
        "    for (images,labels) in test_loader:\n",
        "      images, labels = images.to(device),labels.to(device)#sending data to CPU or GPU as per device\n",
        "      outputs = model(images) # forward pass, result captured in outputs (plural as there are many images in a batch)\n",
        "      # the outputs are in batch size x one hot vector \n",
        "      preds = outputs.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "      output_match_list = preds.eq(labels.view_as(preds)).squeeze().tolist()\n",
        "      labels_list = labels.squeeze().tolist()\n",
        "      preds_list = preds.squeeze().tolist()\n",
        "\n",
        "      for index, bool_value in enumerate(output_match_list):\n",
        "        if not bool_value:\n",
        "          list_misclassified_images.append((images[index],labels[index],preds[index]))\n",
        "          if len(list_misclassified_images) == num_image: break\n",
        "      if len(list_misclassified_images) == num_image: break\n",
        "  return list_misclassified_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMZVaMU8LsBK"
      },
      "outputs": [],
      "source": [
        "# Plotting misclassified images function\n",
        "def plot_misclassified_images (list_misclassified_images):\n",
        "  figure = plt.figure(figsize = (10,5))\n",
        "  for index in range(1, len(list_misclassified_images) + 1): \n",
        "      plt.subplot(2, int(len(list_misclassified_images)/2), index)\n",
        "      plt.axis('off')\n",
        "      plt.imshow(list_misclassified_images[index-1][0].cpu().numpy().squeeze(), cmap='gray_r')\n",
        "      plt.title(f'Actual - {list_misclassified_images[index-1][1]} \\nPredicted - {list_misclassified_images[index-1][2].cpu().item()}')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l18LPUrn42oJ"
      },
      "outputs": [],
      "source": [
        "#@title Plot Misclassified Images\n",
        "\n",
        "for norm in list_norm:\n",
        "  print(f'\\n=========Misclassified Images for {mapping_dict[norm]}.========\\n')\n",
        "  list_misclassified_images = get_misclassified_images(dict_training_output[norm]['model'],device, test_loader,num_image = 10)\n",
        "  plot_misclassified_images(list_misclassified_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96ggmVA6HcXM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPbJUohnS4ha9urG6vZUXX",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}